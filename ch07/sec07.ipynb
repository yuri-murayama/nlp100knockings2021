{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7af9e1b0",
   "metadata": {},
   "source": [
    "# 60. 単語ベクトルの読み込みと表示Permalink\n",
    "### Google Newsデータセット（約1,000億単語）での学習済み単語ベクトル（300万単語・フレーズ，300次元）をダウンロードし，”United States”の単語ベクトルを表示せよ．ただし，”United States”は内部的には”United_States”と表現されていることに注意せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a806766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb0f5022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"United_States\" vector:  [-3.61328125e-02 -4.83398438e-02  2.35351562e-01  1.74804688e-01\n",
      " -1.46484375e-01 -7.42187500e-02 -1.01562500e-01 -7.71484375e-02\n",
      "  1.09375000e-01 -5.71289062e-02 -1.48437500e-01 -6.00585938e-02\n",
      "  1.74804688e-01 -7.71484375e-02  2.58789062e-02 -7.66601562e-02\n",
      " -3.80859375e-02  1.35742188e-01  3.75976562e-02 -4.19921875e-02\n",
      " -3.56445312e-02  5.34667969e-02  3.68118286e-04 -1.66992188e-01\n",
      " -1.17187500e-01  1.41601562e-01 -1.69921875e-01 -6.49414062e-02\n",
      " -1.66992188e-01  1.00585938e-01  1.15722656e-01 -2.18750000e-01\n",
      " -9.86328125e-02 -2.56347656e-02  1.23046875e-01 -3.54003906e-02\n",
      " -1.58203125e-01 -1.60156250e-01  2.94189453e-02  8.15429688e-02\n",
      "  6.88476562e-02  1.87500000e-01  6.49414062e-02  1.15234375e-01\n",
      " -2.27050781e-02  3.32031250e-01 -3.27148438e-02  1.77734375e-01\n",
      " -2.08007812e-01  4.54101562e-02 -1.23901367e-02  1.19628906e-01\n",
      "  7.44628906e-03 -9.03320312e-03  1.14257812e-01  1.69921875e-01\n",
      " -2.38281250e-01 -2.79541016e-02 -1.21093750e-01  2.47802734e-02\n",
      "  7.71484375e-02 -2.81982422e-02 -4.71191406e-02  1.78222656e-02\n",
      " -1.23046875e-01 -5.32226562e-02  2.68554688e-02 -3.11279297e-02\n",
      " -5.59082031e-02 -5.00488281e-02 -3.73535156e-02  1.25976562e-01\n",
      "  5.61523438e-02  1.51367188e-01  4.29687500e-02 -2.08007812e-01\n",
      " -4.78515625e-02  2.78320312e-02  1.81640625e-01  2.20703125e-01\n",
      " -3.61328125e-02 -8.39843750e-02 -3.69548798e-05 -9.52148438e-02\n",
      " -1.25000000e-01 -1.95312500e-01 -1.50390625e-01 -4.15039062e-02\n",
      "  1.31835938e-01  1.17675781e-01  1.91650391e-02  5.51757812e-02\n",
      " -9.42382812e-02 -1.08886719e-01  7.32421875e-02 -1.15234375e-01\n",
      "  8.93554688e-02 -1.40625000e-01  1.45507812e-01  4.49218750e-02\n",
      " -1.10473633e-02 -1.62353516e-02  4.05883789e-03  3.75976562e-02\n",
      " -6.98242188e-02 -5.46875000e-02  2.17285156e-02 -9.47265625e-02\n",
      "  4.24804688e-02  1.81884766e-02 -1.73339844e-02  4.63867188e-02\n",
      " -1.42578125e-01  1.99218750e-01  1.10839844e-01  2.58789062e-02\n",
      " -7.08007812e-02 -5.54199219e-02  3.45703125e-01  1.61132812e-01\n",
      " -2.44140625e-01 -2.59765625e-01 -9.71679688e-02  8.00781250e-02\n",
      " -8.78906250e-02 -7.22656250e-02  1.42578125e-01 -8.54492188e-02\n",
      " -3.18359375e-01  8.30078125e-02  6.34765625e-02  1.64062500e-01\n",
      " -1.92382812e-01 -1.17675781e-01 -5.41992188e-02 -1.56250000e-01\n",
      " -1.21582031e-01 -4.95605469e-02  1.20117188e-01 -3.83300781e-02\n",
      "  5.51757812e-02 -8.97216797e-03  4.32128906e-02  6.93359375e-02\n",
      "  8.93554688e-02  2.53906250e-01  1.65039062e-01  1.64062500e-01\n",
      " -1.41601562e-01  4.58984375e-02  1.97265625e-01 -8.98437500e-02\n",
      "  3.90625000e-02 -1.51367188e-01 -8.60595703e-03 -1.17675781e-01\n",
      " -1.97265625e-01 -1.12792969e-01  1.29882812e-01  1.96289062e-01\n",
      "  1.56402588e-03  3.93066406e-02  2.17773438e-01 -1.43554688e-01\n",
      "  6.03027344e-02 -1.35742188e-01  1.16210938e-01 -1.59912109e-02\n",
      "  2.79296875e-01  1.46484375e-01 -1.19628906e-01  1.76757812e-01\n",
      "  1.28906250e-01 -1.49414062e-01  6.93359375e-02 -1.72851562e-01\n",
      "  9.22851562e-02  1.33056641e-02 -2.00195312e-01 -9.76562500e-02\n",
      " -1.65039062e-01 -2.46093750e-01 -2.35595703e-02 -2.11914062e-01\n",
      "  1.84570312e-01 -1.85546875e-02  2.16796875e-01  5.05371094e-02\n",
      "  2.02636719e-02  4.25781250e-01  1.28906250e-01 -2.77099609e-02\n",
      "  1.29882812e-01 -1.15722656e-01 -2.05078125e-02  1.49414062e-01\n",
      "  7.81250000e-03 -2.05078125e-01 -8.05664062e-02 -2.67578125e-01\n",
      " -2.29492188e-02 -8.20312500e-02  8.64257812e-02  7.61718750e-02\n",
      " -3.66210938e-02  5.22460938e-02 -1.22070312e-01 -1.44042969e-02\n",
      " -2.69531250e-01  8.44726562e-02 -2.52685547e-02 -2.96630859e-02\n",
      " -1.68945312e-01  1.93359375e-01 -1.08398438e-01  1.94091797e-02\n",
      " -1.80664062e-01  1.93359375e-01 -7.08007812e-02  5.85937500e-02\n",
      " -1.01562500e-01 -1.31835938e-01  7.51953125e-02 -7.66601562e-02\n",
      "  3.37219238e-03 -8.59375000e-02  1.25000000e-01  2.92968750e-02\n",
      "  1.70898438e-01 -9.37500000e-02 -1.09375000e-01 -2.50244141e-02\n",
      "  2.11914062e-01 -4.44335938e-02  6.12792969e-02  2.62451172e-02\n",
      " -1.77734375e-01  1.23046875e-01 -7.42187500e-02 -1.67968750e-01\n",
      " -1.08886719e-01 -9.04083252e-04 -7.37304688e-02  5.49316406e-02\n",
      "  6.03027344e-02  8.39843750e-02  9.17968750e-02 -1.32812500e-01\n",
      "  1.22070312e-01 -8.78906250e-03  1.19140625e-01 -1.94335938e-01\n",
      " -6.64062500e-02 -2.07031250e-01  7.37304688e-02  8.93554688e-02\n",
      "  1.81884766e-02 -1.20605469e-01 -2.61230469e-02  2.67333984e-02\n",
      "  7.76367188e-02 -8.30078125e-02  6.78710938e-02 -3.54003906e-02\n",
      "  3.10546875e-01 -2.42919922e-02 -1.41601562e-01 -2.08007812e-01\n",
      " -4.57763672e-03 -6.54296875e-02 -4.95605469e-02  2.22656250e-01\n",
      "  1.53320312e-01 -1.38671875e-01 -5.24902344e-02  4.24804688e-02\n",
      " -2.38281250e-01  1.56250000e-01  5.83648682e-04 -1.20605469e-01\n",
      " -9.22851562e-02 -4.44335938e-02  3.61328125e-02 -1.86767578e-02\n",
      " -8.25195312e-02 -8.25195312e-02 -4.05273438e-02  1.19018555e-02\n",
      "  1.69921875e-01 -2.80761719e-02  3.03649902e-03  9.32617188e-02\n",
      " -8.49609375e-02  1.57470703e-02  7.03125000e-02  1.62353516e-02\n",
      " -2.27050781e-02  3.51562500e-02  2.47070312e-01 -2.67333984e-02]\n"
     ]
    }
   ],
   "source": [
    "print('\"United_States\" 単語ベクトル: ', model['United_States'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8380a8",
   "metadata": {},
   "source": [
    "# 61. 単語の類似度Permalink\n",
    "### “United States”と”U.S.”のコサイン類似度を計算せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aacedb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“United States”と”U.S.”のコサイン類似度: 0.73107743\n"
     ]
    }
   ],
   "source": [
    "print(\"“United States”と”U.S.”のコサイン類似度:\",model.similarity('United_States', 'U.S.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d4d45",
   "metadata": {},
   "source": [
    "# 62. 類似度の高い単語10件\n",
    "### “United States”とコサイン類似度が高い10語と，その類似度を出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6efcb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“United States”とコサイン類似度が高い10語: [('Unites_States', 0.7877248525619507), ('Untied_States', 0.7541370391845703), ('United_Sates', 0.74007248878479), ('U.S.', 0.7310774326324463), ('theUnited_States', 0.6404393911361694), ('America', 0.6178410053253174), ('UnitedStates', 0.6167312264442444), ('Europe', 0.6132988929748535), ('countries', 0.6044804453849792), ('Canada', 0.6019070148468018)]\n"
     ]
    }
   ],
   "source": [
    "print(\"“United States”とコサイン類似度が高い10語:\",model.most_similar('United_States', topn=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0798adfa",
   "metadata": {},
   "source": [
    "# 63. 加法構成性によるアナロジー\n",
    "### “Spain”の単語ベクトルから”Madrid”のベクトルを引き，”Athens”のベクトルを足したベクトルを計算し，そのベクトルと類似度の高い10語とその類似度を出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad7dbb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Spains', 0.6056790947914124), ('Barcelona', 0.6044401526451111), ('Spaniards', 0.5837482213973999), ('Málaga', 0.5805597305297852), ('Malaga', 0.5797936916351318), ('Spanish', 0.5793160200119019), ('Catalan', 0.568308413028717), ('San_Sebastián', 0.5657953023910522), ('Salave_Gold_Deposit', 0.5624399185180664), ('Inveravante_Inversiones_SL', 0.5606337189674377)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(positive=['Spain','Madrid'],negative=['Athens'],topn=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8d4e18",
   "metadata": {},
   "source": [
    "# 64. アナロジーデータでの実験Permalink\n",
    "### 単語アナロジーの評価データをダウンロードし，vec(2列目の単語) - vec(1列目の単語) + vec(3列目の単語)を計算し，そのベクトルと類似度が最も高い単語と，その類似度を求めよ．求めた単語と類似度は，各事例の末尾に追記せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18379ca4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'a' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-30e308819fb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m            \u001b[0mnew_lines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mnew_lines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'a' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "new_lines = []\n",
    "with open('questions-words.txt') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        #print(line)\n",
    "        if line.startswith(':'):\n",
    "           new_lines.append(line)\n",
    "        else:\n",
    "            word, score = model.most_similar(positive=[line[1], line[2]], negative=[line[0]], topn=1)[0]\n",
    "            new_lines.append(line+' '+word+' '+str(score))\n",
    "print(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07da351",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('analogy.txt', 'w') as f:\n",
    "    f.write('\\n'.join(new_lines))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
