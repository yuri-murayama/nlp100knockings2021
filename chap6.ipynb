{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#50\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#参考にしたサイト\n",
    "#(50.1)https://note.nkmk.me/python-pandas-read-csv-tsv/\n",
    "\n",
    "df = pd.read_table(\"chap06/newsCorpora.csv\", header=None, names=(\"ID\",\"TITLE\",\"URL\",\"PUBLISHER\",\"CATEGORY\",\"STORY\",\"HOSTNAME\",\"TIMESTAMP\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(50.2)https://note.nkmk.me/python-pandas-query/\n",
    "\n",
    "df_50_2 = df[df[\"PUBLISHER\"].isin([\"Reuters\",\"Huffington Post\",\"Businessweek\",\"Contactmusic.com\",\"Daily Mail\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(50.3)https://note.nkmk.me/python-pandas-random-sort-shuffle/\n",
    "\n",
    "df_50_3 = df_50_2.sample(frac=1,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 10672\n",
      "valid: 1334\n",
      "test: 1334\n"
     ]
    }
   ],
   "source": [
    "#(50.4)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "##まず80%(学習データ)と20%(検証データ+評価データ)にわける\n",
    "train,valid_test = train_test_split(df_50_3,test_size=0.2,random_state=0)\n",
    "\n",
    "##つぎに、20%を検証データと評価データにわける\n",
    "valid,test = train_test_split(valid_test,test_size=0.5,random_state=0)\n",
    "\n",
    "##念のため大きさを確認する\n",
    "print(\"train: %d\" % (len(train)))\n",
    "print(\"valid: %d\" % (len(valid)))\n",
    "print(\"test: %d\" % (len(test)))\n",
    "\n",
    "##ファイル書き出し\n",
    "##https://note.nkmk.me/python-pandas-to-csv/\n",
    "train.to_csv(\"chap06/train.txt\",columns=[\"CATEGORY\",\"TITLE\"],sep=\"\\t\",header=False,index=False)\n",
    "valid.to_csv(\"chap06/valid.txt\",columns=[\"CATEGORY\",\"TITLE\"],sep=\"\\t\",header=False,index=False)\n",
    "test.to_csv(\"chap06/test.txt\",columns=[\"CATEGORY\",\"TITLE\"],sep=\"\\t\",header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*train\n",
      "b    4473\n",
      "e    4233\n",
      "t    1235\n",
      "m     731\n",
      "Name: CATEGORY, dtype: int64\n",
      "*valid\n",
      "b    583\n",
      "e    533\n",
      "t    123\n",
      "m     95\n",
      "Name: CATEGORY, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "##各カテゴリの事例数確認\n",
    "##https://note.nkmk.me/python-pandas-value-counts/\n",
    "print(\"*train\")\n",
    "print(train[\"CATEGORY\"].value_counts())\n",
    "print(\"*valid\")\n",
    "print(valid[\"CATEGORY\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#51\n",
    "#記事のタイトルに出てくる単語をカウントして特徴量にする\n",
    "#参考にしたサイト\n",
    "#https://qiita.com/fujin/items/b1a7152c2ec2b4963160\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "vec_count = CountVectorizer()\n",
    "\n",
    "##学習データ\n",
    "vec_count.fit(train[\"TITLE\"])\n",
    "train_feature = vec_count.transform(train[\"TITLE\"])\n",
    "#print(vec_count.vocabulary_)\n",
    "#print(len(vec_count.vocabulary_))\n",
    "np.savetxt(\"chap06/train_feature.txt\", train_feature.toarray(), fmt=\"%d\")\n",
    "\n",
    "##検証データ\n",
    "vec_count.fit(valid[\"TITLE\"])\n",
    "valid_feature = vec_count.transform(valid[\"TITLE\"])\n",
    "#print(vec_count.vocabulary_)\n",
    "#print(len(vec_count.vocabulary_))\n",
    "np.savetxt(\"chap06/valid_feature.txt\", valid_feature.toarray(), fmt=\"%d\")\n",
    "\n",
    "##評価データ\n",
    "vec_count.fit(test[\"TITLE\"])\n",
    "test_feature = vec_count.transform(test[\"TITLE\"])\n",
    "#print(vec_count.vocabulary_)\n",
    "#print(len(vec_count.vocabulary_))\n",
    "np.savetxt(\"chap06/test_feature.txt\", test_feature.toarray(), fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayano/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 52\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_feature, train['CATEGORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
